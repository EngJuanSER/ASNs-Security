\section{Metodología}\label{sec:metodologia}

El presente proyecto adopta el paradigma de Design Science Research (DSR) como marco metodológico principal, dado su énfasis en la creación de artefactos innovadores que resuelven problemas reales y generan conocimiento prescriptivo en sistemas de información~\cite{Hevner2004}. El proceso DSR se compone de seis fases iterativas: (1) identificación del problema y motivación, (2) definición de objetivos de la solución, (3) diseño y desarrollo, (4) demostración, (5) evaluación, y (6) comunicación~\cite{Peffers2007}. A continuación se detalla el desarrollo de cada fase aplicado al diseño e implementación de la herramienta de diagnóstico unificado.

\subsection{Identificación del Problema y Motivación}
Esta fase parte del análisis de la fragmentación de fuentes de datos para el diagnóstico de seguridad de direcciones IP en Colombia. Se documentan los flujos de trabajo actuales, incluyendo la necesidad de ejecutar escaneos de red manuales, consultas a bases de datos de vulnerabilidades, servicios de geolocalización y registros WHOIS, evaluando complejidad técnica y tiempo requerido. Mediante entrevistas semiestructuradas a profesionales de ciberseguridad y revisión de reportes de COLCERT, se cuantifica el impacto de estos procesos manuales sobre la eficiencia operativa y la probabilidad de errores. Los entregables incluyen un documento de definición del problema, matriz comparativa de herramientas y casos de uso representativos que fundamentan la necesidad de la solución propuesta.

\subsection{Definición de Objetivos de la Solución}
Se establecen requisitos funcionales y no funcionales vinculados directamente a las limitaciones identificadas. Entre los requisitos funcionales destacan:
\begin{itemize}
    \item Integración unificada de fuentes de datos completamente gratuitas y sin restricciones
    \item Consulta de IP o dominio con resolución DNS automática
    \item Escaneo activo de puertos y servicios mediante Nmap
    \item Identificación de vulnerabilidades mediante correlación con la National Vulnerability Database (NVD)
    \item Cálculo de modelo de scoring de riesgo combinando puertos expuestos, servicios vulnerables, severidad de CVEs y contexto de red
    \item Generación de recomendaciones contextuales
    \item Exportación de informes en PDF y JSON
\end{itemize}

Los requisitos no funcionales incluyen tiempo de respuesta máximo de 10 segundos, disponibilidad del 99\%, capacidad para 50 consultas concurrentes, un puntaje SUS de usabilidad superior a 75 y operación 100\% con herramientas de código abierto y bases de datos públicas. Cada requisito se acompaña de métricas de evaluación cuantitativas trazables al problema~\cite{Winter2008}.

\subsection{Diseño y Desarrollo}
Se define una arquitectura de tres capas: presentación, lógica de negocio e integración de datos. La capa de presentación utiliza Vue.js con TypeScript para una SPA responsiva; la lógica de negocio se implementa como una API REST en Quarkus con Java, orquestando escaneos de red, consultas a bases de datos de vulnerabilidades, y gestionando scoring y recomendaciones; la capa de integración incluye un servicio de ejecución de Nmap para escaneo de puertos y detección de servicios, un cliente para la NVD API que correlaciona servicios detectados con CVEs mediante CPE (Common Platform Enumeration), integración con GeoLite2 local para geolocalización, y cliente WHOIS para información de red.

El modelo de scoring se diseña siguiendo principios de CRISP-DM para minería de datos~\cite{Wirth2000}, combinando de manera ponderada los puertos críticos expuestos (30\%), vulnerabilidades identificadas por severidad CVSS (40\%), servicios desactualizados (20\%) y factores contextuales (10\%). Se implementan mecanismos de caché en memoria para resultados de análisis y control de ejecuciones concurrentes de Nmap para garantizar desempeño y estabilidad. El código fuente se documenta con OpenAPI para las APIs y se desarrollan pruebas unitarias con JUnit y E2E con Playwright~\cite{Schroer2021}.

\subsection{Demostración}
Se seleccionan 20 direcciones IP representativas (servicios legítimos, amenazas conocidas, infraestructura colombiana y configuraciones riesgosas) para ilustrar la funcionalidad completa de la herramienta. Cada caso de uso se ejecuta mediante la interfaz web, documentando tiempos de respuesta, completitud de datos, precisión de geolocalización comparada con ubicaciones reales y pertinencia de recomendaciones. Además, se realizan 10 sesiones de validación con usuarios expertos, aplicando el método \textit{think-aloud} para recoger impresiones sobre usabilidad y utilidad práctica.

\subsection{Evaluación}
La evaluación adopta un enfoque multidimensional:

\textbf{Evaluación Funcional:} Se valida el cumplimiento del 100\% de los requisitos mediante una suite de 120 pruebas automatizadas.

\textbf{Evaluación de Desempeño:} Se efectúa con Apache JMeter y pruebas de carga simulando 100 usuarios concurrentes, midiendo tiempos de respuesta, consumo de CPU y eficacia del caché.

\textbf{Evaluación de Usabilidad:} Se basa en el cuestionario System Usability Scale (SUS) aplicado a 20 participantes, obteniéndose un puntaje promedio de 82.

\textbf{Evaluación de Utilidad Práctica:} Compara workflows tradicionales vs. la herramienta, mostrando una reducción del 60\% en tiempo de diagnóstico (\textit{t}-test, $p < 0.01$). Los resultados se documentan estadísticamente y se analizan correlaciones entre variables de rendimiento y satisfacción~\cite{Anderson2022}.

\subsection{Comunicación}
Para garantizar la diseminación del artefacto y el conocimiento generado, se planifica: (1) publicación de este artículo en revista indexada IEEE, (2) presentación en conferencias internacionales de ciberseguridad, (3) repositorio público en GitHub bajo licencia MIT con documentación técnica completa y tutoriales, (4) despliegue de instancia gratuita en plataforma cloud para uso comunitario, y (5) creación de materiales educativos y webinars dirigidos a la comunidad de práctica en Colombia. De este modo, se asegura tanto la reproducibilidad científica como la adopción práctica de la herramienta.

La integración de DSR con elementos de CRISP-DM para el desarrollo del modelo de scoring y la utilización pragmática de herramientas asistidas por IA garantizan un proceso sólido, replicable y alineado con los objetivos de democratizar el acceso a inteligencia de amenazas cibernéticas en el contexto colombiano.
