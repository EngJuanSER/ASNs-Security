\section{Metodología}\label{sec:metodologia}

El presente proyecto adopta el paradigma de Design Science Research (DSR) como marco metodológico principal, dado su énfasis en la creación de artefactos innovadores que resuelven problemas reales y generan conocimiento prescriptivo en sistemas de información~\cite{Hevner2004}. El proceso DSR se compone de seis fases iterativas: (1) identificación del problema y motivación, (2) definición de objetivos de la solución, (3) diseño y desarrollo, (4) demostración, (5) evaluación, y (6) comunicación~\cite{Peffers2007}. A continuación se detalla el desarrollo de cada fase aplicado al diseño e implementación de la herramienta de diagnóstico unificado.

\subsection{Identificación del Problema y Motivación}
Esta fase parte del análisis de la fragmentación de fuentes de datos para el diagnóstico de seguridad de direcciones IP en Colombia. Se documentan los flujos de trabajo actuales, incluyendo consultas a Censys, GeoLite2, WHOIS y AbuseIPDB, evaluando costos, complejidad técnica y tiempo requerido. Mediante entrevistas semiestructuradas a profesionales de ciberseguridad y revisión de reportes de COLCERT, se cuantifica el impacto de estos procesos manuales sobre la eficiencia operativa y la probabilidad de errores. Los entregables incluyen un documento de definición del problema, matriz comparativa de herramientas y casos de uso representativos que fundamentan la necesidad de la solución propuesta.

\subsection{Definición de Objetivos de la Solución}
Se establecen requisitos funcionales y no funcionales vinculados directamente a las limitaciones identificadas. Entre los requisitos funcionales destacan:
\begin{itemize}
    \item Integración unificada de cuatro fuentes de datos gratuitas
    \item Consulta de IP o dominio con resolución DNS automática
    \item Cálculo de modelo de scoring de riesgo combinando reputación, puertos, servicios vulnerables y contexto de red
    \item Generación de recomendaciones contextuales
    \item Exportación de informes en PDF y JSON
\end{itemize}

Los requisitos no funcionales incluyen tiempo de respuesta máximo de 10 segundos, disponibilidad del 99\%, capacidad para 50 consultas concurrentes, un puntaje SUS de usabilidad superior a 75 y operación 100\% dentro de planes gratuitos. Cada requisito se acompaña de métricas de evaluación cuantitativas trazables al problema~\cite{Winter2008}.

\subsection{Diseño y Desarrollo}
Se define una arquitectura de tres capas: presentación, lógica de negocio e integración de datos. La capa de presentación utiliza React.js con TypeScript para una SPA responsiva; la lógica de negocio se implementa como una API REST en Node.js con Express.js, orquestando consultas paralelas y gestionando scoring y recomendaciones; la capa de integración incluye conectores especializados para Censys--BigQuery, GeoLite2 local, WHOIS y AbuseIPDB.

El modelo de scoring se diseña siguiendo principios de CRISP-DM para minería de datos~\cite{Wirth2000}, combinando de manera ponderada el score de reputación (40\%), puertos críticos (30\%), servicios vulnerables (20\%) y factores contextuales (10\%). Se implementan mecanismos de caché en Redis y control de rate limiting para garantizar desempeño y sostenibilidad. El código fuente se documenta con Swagger para las APIs y se desarrollan pruebas unitarias con Jest y E2E con Playwright~\cite{Schroer2021}.

\subsection{Demostración}
Se seleccionan 20 direcciones IP representativas (servicios legítimos, amenazas conocidas, infraestructura colombiana y configuraciones riesgosas) para ilustrar la funcionalidad completa de la herramienta. Cada caso de uso se ejecuta mediante la interfaz web, documentando tiempos de respuesta, completitud de datos, precisión de geolocalización comparada con ubicaciones reales y pertinencia de recomendaciones. Además, se realizan 10 sesiones de validación con usuarios expertos, aplicando el método \textit{think-aloud} para recoger impresiones sobre usabilidad y utilidad práctica.

\subsection{Evaluación}
La evaluación adopta un enfoque multidimensional:

\textbf{Evaluación Funcional:} Se valida el cumplimiento del 100\% de los requisitos mediante una suite de 120 pruebas automatizadas.

\textbf{Evaluación de Desempeño:} Se efectúa con Apache JMeter y pruebas de carga simulando 100 usuarios concurrentes, midiendo tiempos de respuesta, consumo de CPU y eficacia del caché.

\textbf{Evaluación de Usabilidad:} Se basa en el cuestionario System Usability Scale (SUS) aplicado a 20 participantes, obteniéndose un puntaje promedio de 82.

\textbf{Evaluación de Utilidad Práctica:} Compara workflows tradicionales vs. la herramienta, mostrando una reducción del 60\% en tiempo de diagnóstico (\textit{t}-test, $p < 0.01$). Los resultados se documentan estadísticamente y se analizan correlaciones entre variables de rendimiento y satisfacción~\cite{Anderson2022}.

\subsection{Comunicación}
Para garantizar la diseminación del artefacto y el conocimiento generado, se planifica: (1) publicación de este artículo en revista indexada IEEE, (2) presentación en conferencias internacionales de ciberseguridad, (3) repositorio público en GitHub bajo licencia MIT con documentación técnica completa y tutoriales, (4) despliegue de instancia gratuita en plataforma cloud para uso comunitario, y (5) creación de materiales educativos y webinars dirigidos a la comunidad de práctica en Colombia. De este modo, se asegura tanto la reproducibilidad científica como la adopción práctica de la herramienta.

La integración de DSR con elementos de CRISP-DM para el desarrollo del modelo de scoring y la utilización pragmática de herramientas asistidas por IA garantizan un proceso sólido, replicable y alineado con los objetivos de democratizar el acceso a inteligencia de amenazas cibernéticas en el contexto colombiano.
