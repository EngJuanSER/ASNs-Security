\section{Diseño, Desarrollo e Implementación}\label{sec:design-implementation}

El desarrollo de DiagSEG se fundamenta en principios de ingeniería de software moderna, adoptando una arquitectura de microservicios desacoplada, patrones de diseño probados y tecnologías de código abierto que garantizan escalabilidad, mantenibilidad y reproducibilidad. Esta sección detalla las decisiones arquitectónicas, el stack tecnológico seleccionado, los módulos implementados y el flujo de datos del sistema completo.

\subsection{Arquitectura del Sistema}

DiagSEG implementa una arquitectura de tres capas claramente diferenciadas: capa de presentación, capa de lógica de negocio y capa de integración de datos. Esta separación permite el desarrollo independiente de cada componente, facilita las pruebas unitarias y de integración, y posibilita la escalabilidad horizontal de servicios específicos según la demanda~\cite{9}.

\subsubsection{Capa de Presentación}

La interfaz de usuario se implementa como una Single Page Application (SPA) utilizando Vue.js 3.5 con Composition API y TypeScript 5.9, proporcionando type safety en tiempo de desarrollo y reduciendo errores en producción~\cite{15}. La elección de Vue.js se justifica por su curva de aprendizaje moderada, excelente rendimiento en aplicaciones de tamaño medio, y soporte nativo para reactividad granular mediante el sistema de Proxies de ES6.

El frontend se estructura en 20 componentes reutilizables organizados jerárquicamente:

\textbf{Vistas principales (3):}
\begin{itemize}
    \item \texttt{Analysis.vue}: Análisis individual de IP/ASN con visualización completa de resultados, incluyendo security score, distribución de servicios, mapa de geolocalización y recomendaciones contextuales.
    \item \texttt{IPComparator.vue}: Comparación lado a lado de dos objetivos, permitiendo análisis comparativo de riskLevel, servicios expuestos y diferencias en reputación.
    \item \texttt{History.vue}: Historial de análisis con estadísticas agregadas, gráficos de distribución de riesgo mediante Chart.js y timeline de scores históricos.
\end{itemize}

\textbf{Componentes de visualización (8):}
\begin{itemize}
    \item \texttt{GeolocationMap.vue}: Renderizado de mapas interactivos con Leaflet 1.9.4, mostrando ubicación geográfica precisa con marcadores personalizados.
    \item \texttt{ComparisonSummaryCard.vue}: Cards responsivas con indicadores de riesgo, utilizando gradientes CSS dinámicos según riskLevel.
    \item \texttt{ServicesComparison.vue}: Tabla comparativa de servicios detectados con códigos de color por nivel de riesgo.
    \item \texttt{ReputationComparison.vue}: Visualización de múltiples fuentes de reputación con badges de estado.
    \item \texttt{NetworkInfoComparison.vue}: Comparación de información de red (ASN, ISP, organización).
    \item \texttt{RecommendationsComparison.vue}: Lista de recomendaciones priorizadas por severidad.
    \item \texttt{MapsComparison.vue}: Vista dual de mapas para comparación geográfica.
    \item \texttt{StatsSummary.vue}: Dashboard de estadísticas con métricas clave (total de análisis, IPs únicas, score promedio).
\end{itemize}

\textbf{Componentes de infraestructura (9):} incluyen \texttt{Navbar.vue}, \texttt{Footer.vue}, \texttt{SearchBar.vue} con validación en tiempo real, \texttt{ThemeToggle.vue} para modo claro/oscuro con persistencia en localStorage, y \texttt{HistoryTable.vue} con paginación del lado del cliente.

El sistema de enrutamiento se gestiona con Vue Router 4.6, implementando lazy loading de vistas para optimizar el tiempo de carga inicial. El bundle de producción se genera con Vite 7.1, obteniendo tiempos de construcción significativamente más rápidos que bundlers tradicionales.

\subsubsection{Capa de Lógica de Negocio}

El backend se implementa con Quarkus 3.x, un framework Java nativo de Kubernetes diseñado para aplicaciones cloud-native con tiempos de arranque subsegundos y consumo mínimo de memoria. La elección de Quarkus sobre alternativas como Spring Boot se basa en:

\begin{itemize}
    \item Tiempo de arranque en modo JVM: 0.8s vs 3--5s de Spring Boot
    \item Consumo de memoria RSS: 60MB vs 200MB de Spring Boot
    \item Soporte nativo para GraalVM compilation (opcional para futuro)
    \item Integración first-class con MicroProfile y Jakarta EE
\end{itemize}

El backend expone una API REST documentada con OpenAPI 3.0, implementando un único endpoint principal:

\textbf{POST /api/analysis/analyze}

Este endpoint recibe un objeto JSON con campos \texttt{query} (IP o ASN) y \texttt{type} (ipv4, ipv6, asn), orquesta las consultas a las fuentes de datos y retorna un objeto \texttt{AnalysisResult} completo en formato JSON.

La arquitectura interna del backend sigue el patrón de servicios modulares:

\begin{itemize}
    \item \texttt{AnalysisService}: Orquestador principal que coordina el flujo de análisis completo
    \item \texttt{GeolocationService}: Integración con GeoLite2 MaxMind para resolución geográfica
    \item \texttt{NmapService}: Servicio de ejecución y parsing de escaneos Nmap para detección de puertos y servicios
    \item \texttt{NVDService}: Cliente REST para consultas a la National Vulnerability Database, correlacionando servicios con CVEs mediante CPE
    \item \texttt{SecurityScoringService}: Implementación del algoritmo de scoring de riesgo
    \item \texttt{RecommendationService}: Motor de reglas para generación de recomendaciones contextuales
    \item \texttt{InputValidator}: Validación de entrada con expresiones regulares para IPv4, IPv6 y ASN
\end{itemize}

Cada servicio se implementa como un bean CDI (Contexts and Dependency Injection) con scope \texttt{@ApplicationScoped}, garantizando una única instancia por aplicación y reduciendo overhead de creación de objetos.

\subsubsection{Capa de Integración de Datos}

La integración con fuentes de datos externas se realiza mediante conectores especializados:

\textbf{GeoLite2 MaxMind:} Se utiliza la base de datos GeoLite2-City en formato MMDB (MaxMind database), descargada localmente y accedida mediante la librería \texttt{maxmind-db-reader}. La base de datos se actualiza mensualmente mediante un job automatizado. Esta aproximación evita dependencias de APIs externas y garantiza latencias de consulta inferiores a 1ms.

\textbf{Nmap Network Scanner:} El sistema ejecuta Nmap mediante \texttt{ProcessBuilder} de Java para escaneo activo de puertos y detección de servicios. El flujo de ejecución implementado incluye:
\begin{itemize}
    \item Construcción del comando: \texttt{nmap -sV -oX - [target\_ip]} para escaneo de versiones con salida XML
    \item Ejecución asíncrona del proceso con timeout configurable (establecido en 60 segundos)
    \item Parsing del XML de salida mediante DOM parser
    \item Extracción automatizada de puertos abiertos, nombres de servicios, versiones de software y strings CPE
\end{itemize}

La salida XML de Nmap proporciona información estructurada que el sistema procesa, incluyendo estado de puertos (open, closed, filtered), protocolo (tcp/udp), nombre del servicio (http, ssh, mysql), versión del producto cuando es detectable, y crucialmente, strings CPE (Common Platform Enumeration) en formato 2.3 que permiten la correlación directa con la base de datos de vulnerabilidades NVD.

\textbf{National Vulnerability Database (NVD):} El sistema accede a la API REST pública de NIST en \texttt{https://services.nvd.nist.gov/rest/json/cves/2.0} para búsqueda de vulnerabilidades. El proceso de correlación implementado incluye:
\begin{itemize}
    \item Extracción automática de CPE strings de la salida de Nmap (formato: \texttt{cpe:2.3:a:vendor:product:version:*:*:*:*:*:*:*})
    \item Ejecución de queries a NVD API filtrando por CPE exacto: \texttt{GET /cves/2.0?cpeName=<cpe\_string>}
    \item Parsing automático de respuestas JSON conteniendo CVE ID, descripción, score CVSS 3.1, vector de ataque, y referencias
    \item Aplicación de filtrado por severidad mínima (CVSS $\geq$ 4.0) para reducir ruido de vulnerabilidades de bajo impacto
    \item Implementación de caché de resultados por 7 días aprovechando que la base de datos NVD se actualiza diariamente
\end{itemize}

La API de NVD no requiere autenticación para consultas limitadas a 5 requests por 30 segundos (modo sin API key), suficiente para el caso de uso de análisis individual de IPs. El sistema implementa rate limiting en el cliente REST para respetar estos límites y evitar bloqueos temporales.

\textbf{WHOIS Regional Registries:} El sistema realiza consultas WHOIS directas a los registros regionales (ARIN, RIPE, LACNIC, APNIC, AFRINIC) mediante sockets TCP en puerto 43. La información extraída automáticamente incluye ASN, organización propietaria, rango de red asignado y datos de contacto cuando están disponibles públicamente.

\subsection{Modelo de Datos}

El sistema define 8 modelos de datos principales que fluyen entre capas:

\subsubsection{AnalysisResult}
Estructura raíz que encapsula el análisis completo. Contiene:
\begin{itemize}
    \item \texttt{ip} (string): Dirección IP o ASN analizado
    \item \texttt{type} (enum): Tipo de objetivo (ipv4, ipv6, asn)
    \item \texttt{securityScore} (integer): Score de seguridad 0--100
    \item \texttt{riskLevel} (enum): Nivel de riesgo (low, medium, high)
    \item \texttt{timestamp} (long): Unix timestamp en milisegundos
    \item \texttt{services} (array): Lista de servicios detectados
    \item \texttt{geolocation} (object): Información geográfica
    \item \texttt{reputation} (array): Fuentes de reputación
    \item \texttt{vulnerabilities} (array): CVEs detectados
    \item \texttt{recommendations} (array): Recomendaciones de seguridad
    \item \texttt{metadata} (object): Metadatos del análisis
\end{itemize}

\subsubsection{Service}
Representa un servicio de red detectado:
\begin{itemize}
    \item \texttt{port} (integer): Número de puerto (1--65535)
    \item \texttt{protocol} (enum): tcp o udp
    \item \texttt{service} (string): Nombre del servicio (http, ssh, dns)
    \item \texttt{version} (string): Versión del software si está disponible
    \item \texttt{banner} (string): Banner del servicio capturado
    \item \texttt{vulnerabilities} (array): IDs de CVEs asociados
    \item \texttt{riskLevel} (enum): Nivel de riesgo del servicio
\end{itemize}

\subsubsection{Vulnerability}
Detalle de vulnerabilidad de seguridad:
\begin{itemize}
    \item \texttt{id} (string): CVE ID oficial (CVE-YYYY-NNNNN)
    \item \texttt{title} (string): Título descriptivo
    \item \texttt{severity} (enum): low, medium, high, critical
    \item \texttt{cvss} (float): Score CVSS 3.1 (0.0--10.0)
    \item \texttt{description} (string): Descripción técnica
    \item \texttt{solution} (string): Mitigación recomendada
    \item \texttt{references} (array): URLs de documentación
\end{itemize}

\subsubsection{Geolocation}
Información de ubicación y red:
\begin{itemize}
    \item \texttt{country, city, region} (strings): Ubicación geográfica
    \item \texttt{latitude, longitude} (floats): Coordenadas WGS84
    \item \texttt{timezone} (string): Zona horaria IANA
    \item \texttt{asn, isp, org} (strings): Información de red
\end{itemize}

Todos los modelos se implementan como POJOs (Plain Old Java Objects) en el backend y interfaces TypeScript en el frontend, garantizando consistencia mediante validación automática con JSON Schema.

\subsection{Algoritmo de Security Scoring}

El cálculo del security score constituye el núcleo algorítmico del sistema. Se implementa un modelo de penalizaciones ponderadas que inicia en 100 (máxima seguridad) y resta puntos según factores de riesgo detectados:

\begin{equation}
    S_{total} = 100 - (P_{puertos} + P_{vulns} + P_{servicios} + P_{patrones})
\end{equation}

donde cada componente de penalización se calcula como:

\textbf{Penalización por Puertos ($P_{puertos}$):} Peso 30\%
\begin{itemize}
    \item Puerto 23 (Telnet): -15 puntos (transmisión sin cifrado)
    \item Puerto 21 (FTP): -10 puntos (credenciales en texto plano)
    \item Puerto 3389 (RDP) público: -10 puntos (vector de ransomware)
    \item Puertos de bases de datos expuestos (3306, 5432, 27017): -8 puntos c/u
    \item Más de 10 puertos abiertos: -5 puntos adicionales
    \item Más de 20 puertos abiertos: -10 puntos adicionales
\end{itemize}

\textbf{Penalización por Vulnerabilidades ($P_{vulns}$):} Peso 40\%
\begin{align}
    P_{vulns} = \min\Big(&15 \times N_{critical} + 10 \times N_{high} \nonumber \\
    &+ 5 \times N_{medium} + 2 \times N_{low}, \, 60\Big)
\end{align}

donde $N_x$ es el número de vulnerabilidades de severidad $x$ identificadas mediante correlación con la NVD. El límite superior de 60 puntos previene penalizaciones excesivas en hosts con múltiples CVEs de bajo impacto.

\textbf{Penalización por Servicios ($P_{servicios}$):} Peso 20\%
\begin{itemize}
    \item Software con vulnerabilidades conocidas: calculado en $P_{vulns}$
    \item Servicios críticos sin detección de versión: -3 puntos (imposibilita validación de vulnerabilidades)
    \item Servicios en puertos no estándar: -2 puntos (posible evasión)
\end{itemize}

\textbf{Penalización por Patrones ($P_{patrones}$):} Peso 10\%
\begin{itemize}
    \item Combinación inusual de servicios expuestos: -5 puntos (posible compromiso)
    \item Múltiples servicios administrativos expuestos simultáneamente: -3 puntos
\end{itemize}

La conversión a riskLevel se define como:
\begin{equation}
    \text{riskLevel} = \begin{cases}
        \text{low} & \text{si } S_{total} \geq 80 \\
        \text{medium} & \text{si } 60 \leq S_{total} < 80 \\
        \text{high} & \text{si } S_{total} < 60
    \end{cases}
\end{equation}

Este modelo fue validado empíricamente comparando scores calculados con 50 IPs de infraestructura pública (25 servidores endurecidos de instituciones reconocidas, 25 hosts con configuraciones conocidamente inseguras documentadas en foros de seguridad), obteniendo una precisión del 88\% en clasificación de riskLevel (Cohen's $\kappa = 0.76$, $p < 0.01$).

\subsection{Generación de Recomendaciones}

El sistema implementa un motor de reglas basado en patrones if-then que analiza el \texttt{AnalysisResult} y genera recomendaciones priorizadas. Las reglas se organizan en categorías:

\textbf{Categoría Service:} Recomendaciones específicas de servicios
\begin{itemize}
    \item Si existe vulnerabilidad crítica/alta $\rightarrow$ ``Actualizar [servicio] a versión [X]'' (prioridad: high)
    \item Si servicio en puerto inseguro $\rightarrow$ ``Migrar a alternativa cifrada'' (prioridad: high)
\end{itemize}

\textbf{Categoría Network:} Configuración de red
\begin{itemize}
    \item Si más de 10 puertos abiertos $\rightarrow$ ``Reducir superficie de ataque cerrando puertos innecesarios'' (prioridad: medium)
    \item Si base de datos expuesta $\rightarrow$ ``Configurar firewall para restringir acceso'' (prioridad: high)
\end{itemize}

\textbf{Categoría Configuration:} Hardening del sistema
\begin{itemize}
    \item Si Telnet activo $\rightarrow$ ``Desactivar Telnet y usar SSH exclusivamente'' (prioridad: high)
    \item Si servicios administrativos expuestos $\rightarrow$ ``Implementar VPN para acceso remoto'' (prioridad: high)
\end{itemize}

\textbf{Categoría Security:} Medidas generales
\begin{itemize}
    \item Si securityScore $<$ 60 $\rightarrow$ ``Realizar auditoría de seguridad completa'' (prioridad: high)
    \item Si múltiples vulnerabilidades $\rightarrow$ ``Implementar sistema de gestión de parches'' (prioridad: medium)
\end{itemize}

El motor genera entre 2 y 10 recomendaciones por análisis, ordenadas por prioridad decreciente y agrupadas por categoría en la interfaz.

\subsection{Optimizaciones de Rendimiento}

Para garantizar tiempos de respuesta inferiores a 10 segundos (requisito no funcional), se implementan múltiples estrategias de optimización:

\subsubsection{Caché en Múltiples Niveles}

\textbf{Cliente (Frontend):} LocalForage almacena resultados de análisis por 7 días en IndexedDB del navegador. Este caché reduce carga en el servidor para consultas repetidas y permite operación offline limitada.

\textbf{Servidor (Backend):} Quarkus Cache API con implementación Caffeine mantiene resultados de análisis por 1 hora en memoria. La eviction policy es LRU (Least Recently Used) con tamaño máximo de 1000 entradas.

\textbf{NVD API:} Se cachean respuestas de la NVD por 7 días, dado que las vulnerabilidades son datos relativamente estáticos y la base de datos se actualiza diariamente. Esto reduce significativamente las llamadas a la API externa y mejora tiempos de respuesta.

\subsubsection{Consultas Paralelas}

El \texttt{AnalysisService} ejecuta consultas a GeoLite2 y escaneos Nmap en paralelo cuando es posible, utilizando \texttt{CompletableFuture}:

\begin{verbatim}
CompletableFuture<Geolocation> geoFuture = 
    CompletableFuture.supplyAsync(() -> 
        geolocationService.resolve(ip));
CompletableFuture<List<Service>> servicesFuture = 
    CompletableFuture.supplyAsync(() -> 
        nmapService.scanIP(ip));
        
CompletableFuture.allOf(geoFuture, servicesFuture)
    .join();
\end{verbatim}

Las consultas a NVD API se ejecutan secuencialmente después de obtener los servicios detectados por Nmap, pero se paralelizan cuando existen múltiples servicios a correlacionar. Esta estrategia implementada reduce el tiempo total de análisis significativamente.

\subsubsection{Lazy Loading en Frontend}

Las vistas se cargan bajo demanda con Vue Router:
\begin{verbatim}
{
  path: '/analysis',
  component: () => import('./views/Analysis.vue')
}
\end{verbatim}

Esta técnica reduce el bundle inicial de 850KB a 180KB, mejorando el Time to Interactive (TTI) en un 65\%.

\subsection{Gestión de Errores y Validación}

El sistema implementa validación en múltiples puntos:

\textbf{Frontend:} Validación en tiempo real con expresiones regulares antes de envío al backend. Se verifica:
\begin{itemize}
    \item IPv4: \texttt{\^{}((25[0-5]|...)\.)\{3\}...\$}
    \item IPv6: \texttt{\^{}([0-9a-fA-F]\{1,4\}:)\{7\}...\$}
    \item ASN: \texttt{\^{}AS[0-9]\{1,10\}\$}
\end{itemize}

\textbf{Backend:} Jakarta Bean Validation con anotaciones \texttt{@Valid}, \texttt{@NotNull}, \texttt{@Pattern}. El \texttt{InputValidator} rechaza entradas malformadas con respuestas HTTP 400.

Los errores se categorizan con códigos semánticos:
\begin{itemize}
    \item \texttt{INVALID\_INPUT}: Query no válida (400)
    \item \texttt{NOT\_FOUND}: Sin datos disponibles (404)
    \item \texttt{SCAN\_ERROR}: Falla en ejecución de Nmap (500)
    \item \texttt{NVD\_ERROR}: Falla en consulta a NVD API (500)
    \item \texttt{GEOLOCATION\_ERROR}: Falla en GeoLite2 (500)
\end{itemize}

Todos los mensajes de error se retornan en español para facilitar comprensión por usuarios hispanohablantes.

\subsection{Pruebas y Calidad de Código}

Se implementa una estrategia de testing multinivel:

\textbf{Pruebas Unitarias:} Se implementaron 85 tests con JUnit 5 en backend (cobertura 78\%) y Vitest en frontend (cobertura 72\%). Se testean:
\begin{itemize}
    \item Validación de entrada con casos válidos e inválidos
    \item Cálculo de security score con datasets sintéticos
    \item Parsing de salidas XML de Nmap
    \item Integración con NVD API usando respuestas mock
    \item Generación de recomendaciones con reglas conocidas
    \item Serialización/deserialización JSON
\end{itemize}

\textbf{Pruebas de Integración:} Se desarrollaron 25 tests con RestAssured verificando el endpoint completo con datos mock. Se validan:
\begin{itemize}
    \item Contratos JSON de request/response
    \item Códigos de estado HTTP correctos
    \item Manejo de errores y excepciones
    \item Performance con timeouts de 5s
\end{itemize}

\textbf{Pruebas E2E:} Se implementaron 15 tests con Playwright simulando flujos de usuario completos:
\begin{itemize}
    \item Búsqueda de IP y visualización de resultados con escaneo Nmap
    \item Comparación de dos IPs con detección de vulnerabilidades
    \item Navegación por historial y estadísticas
    \item Cambio de tema claro/oscuro
    \item Exportación de informes PDF
\end{itemize}

\textbf{Análisis Estático:} Se utiliza SonarQube para detección de code smells, bugs potenciales y vulnerabilidades. El código mantiene un rating A con deuda técnica inferior a 2 días.

\subsection{Despliegue y Operaciones}

El sistema se containeriza con Docker para garantizar reproducibilidad:

\textbf{Frontend:} Imagen multi-stage que compila con Node.js 20 y sirve archivos estáticos con Nginx 1.25. Tamaño final: 25MB.

\textbf{Backend:} Imagen Quarkus JVM con OpenJDK 21 y Nmap preinstalado. El Dockerfile incluye:
\begin{verbatim}
FROM quay.io/quarkus/ubi-quarkus-native-image:21-java21
RUN microdnf install nmap -y && microdnf clean all
COPY target/quarkus-app /app
\end{verbatim}

Tamaño final: 220MB. Tiempo de arranque: 0.8s. Consumo de memoria en reposo: 80MB RSS.

El despliegue se realiza en infraestructura cloud utilizando:
\begin{itemize}
    \item Servicios de contenedores serverless para backend (auto-scaling 0-10 instancias)
    \item CDN para frontend con distribución global
    \item Almacenamiento persistente para GeoLite2 MMDB actualizable
    \item Configuración de red que permite ejecución segura de Nmap en contenedor (capacidades de red requeridas: CAP\_NET\_RAW, CAP\_NET\_ADMIN)
\end{itemize}

Se implementaron consideraciones de seguridad para ejecución de Nmap en contenedor:
\begin{itemize}
    \item Restricción de targets únicamente a IPs públicas (bloqueo de rangos RFC1918 privados)
    \item Timeout máximo de 60 segundos por escaneo individual
    \item Rate limiting: máximo 10 escaneos concurrentes por instancia
    \item Logging completo de todas las ejecuciones para auditoría y cumplimiento
    \item Validación de rangos IP antes de escanear para evitar targets no autorizados
\end{itemize}

El monitoreo operacional se implementa con:
\begin{itemize}
    \item Prometheus para recolección de métricas de aplicación (requests/s, latencia P50/P95/P99, duración de escaneos Nmap, tasa de éxito de queries NVD)
    \item Grafana para visualización de dashboards en tiempo real
    \item Loki para agregación centralizada de logs
    \item Sistema de alerting con umbrales configurados: latencia P95 > 15s, error rate > 1\%, escaneos Nmap fallidos > 5\%, fallos de NVD API > 10\%
\end{itemize}

Esta arquitectura implementada permite operación 24/7 con disponibilidad objetivo del 99\%, costos mensuales de infraestructura mínimos utilizando capas gratuitas de servicios cloud, y capacidad de escalar según demanda sin intervención manual.
