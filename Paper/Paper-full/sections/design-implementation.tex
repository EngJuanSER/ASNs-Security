\section{Diseño, Desarrollo e Implementación}\label{sec:design-implementation}

El desarrollo de DiagSEG se fundamenta en principios de ingeniería de software moderna, adoptando una arquitectura de microservicios desacoplada, patrones de diseño probados y tecnologías de código abierto que garantizan escalabilidad, mantenibilidad y reproducibilidad. Esta sección detalla las decisiones arquitectónicas, el stack tecnológico seleccionado, los módulos implementados y el flujo de datos del sistema completo.

\subsection{Arquitectura del Sistema}

DiagSEG implementa una arquitectura de tres capas claramente diferenciadas: capa de presentación, capa de lógica de negocio y capa de integración de datos. Esta separación permite el desarrollo independiente de cada componente, facilita las pruebas unitarias y de integración, y posibilita la escalabilidad horizontal de servicios específicos según la demanda~\cite{9}.

\subsubsection{Capa de Presentación}

La interfaz de usuario se implementa como una Single Page Application (SPA) utilizando Vue.js 3.5 con Composition API y TypeScript 5.9, proporcionando type safety en tiempo de desarrollo y reduciendo errores en producción~\cite{15}. La elección de Vue.js se justifica por su curva de aprendizaje moderada, excelente rendimiento en aplicaciones de tamaño medio, y soporte nativo para reactividad granular mediante el sistema de Proxies de ES6.

El frontend se estructura en 20 componentes reutilizables organizados jerárquicamente:

\textbf{Vistas principales (3):}
\begin{itemize}
    \item \texttt{Analysis.vue}: Análisis individual de IP/ASN con visualización completa de resultados, incluyendo security score, distribución de servicios, mapa de geolocalización y recomendaciones contextuales.
    \item \texttt{IPComparator.vue}: Comparación lado a lado de dos objetivos, permitiendo análisis comparativo de riskLevel, servicios expuestos y diferencias en reputación.
    \item \texttt{History.vue}: Historial de análisis con estadísticas agregadas, gráficos de distribución de riesgo mediante Chart.js y timeline de scores históricos.
\end{itemize}

\textbf{Componentes de visualización (8):}
\begin{itemize}
    \item \texttt{GeolocationMap.vue}: Renderizado de mapas interactivos con Leaflet 1.9.4, mostrando ubicación geográfica precisa con marcadores personalizados.
    \item \texttt{ComparisonSummaryCard.vue}: Cards responsivas con indicadores de riesgo, utilizando gradientes CSS dinámicos según riskLevel.
    \item \texttt{ServicesComparison.vue}: Tabla comparativa de servicios detectados con códigos de color por nivel de riesgo.
    \item \texttt{ReputationComparison.vue}: Visualización de múltiples fuentes de reputación con badges de estado.
    \item \texttt{NetworkInfoComparison.vue}: Comparación de información de red (ASN, ISP, organización).
    \item \texttt{RecommendationsComparison.vue}: Lista de recomendaciones priorizadas por severidad.
    \item \texttt{MapsComparison.vue}: Vista dual de mapas para comparación geográfica.
    \item \texttt{StatsSummary.vue}: Dashboard de estadísticas con métricas clave (total de análisis, IPs únicas, score promedio).
\end{itemize}

\textbf{Componentes de infraestructura (9):} incluyen \texttt{Navbar.vue}, \texttt{Footer.vue}, \texttt{SearchBar.vue} con validación en tiempo real, \texttt{ThemeToggle.vue} para modo claro/oscuro con persistencia en localStorage, y \texttt{HistoryTable.vue} con paginación del lado del cliente.

El sistema de enrutamiento se gestiona con Vue Router 4.6, implementando lazy loading de vistas para optimizar el tiempo de carga inicial. El bundle de producción se genera con Vite 7.1, obteniendo tiempos de construcción significativamente más rápidos que bundlers tradicionales.

\subsubsection{Capa de Lógica de Negocio}

El backend se desarrolla con Quarkus 3.x, un framework Java nativo de Kubernetes diseñado para aplicaciones cloud-native con tiempos de arranque subsegundos y consumo mínimo de memoria. La elección de Quarkus sobre alternativas como Spring Boot se basa en:

\begin{itemize}
    \item Tiempo de arranque en modo JVM: 0.8s vs 3--5s de Spring Boot
    \item Consumo de memoria RSS: 60MB vs 200MB de Spring Boot
    \item Soporte nativo para GraalVM compilation (opcional para futuro)
    \item Integración first-class con MicroProfile y Jakarta EE
\end{itemize}

El backend expone una API REST documentada con OpenAPI 3.0, implementando un único endpoint principal:

\textbf{POST /api/analysis/analyze}

Este endpoint recibe un objeto JSON con campos \texttt{query} (IP o ASN) y \texttt{type} (ipv4, ipv6, asn), orquesta las consultas a las fuentes de datos y retorna un objeto \texttt{AnalysisResult} completo en formato JSON.

La arquitectura interna del backend sigue el patrón de servicios modulares:

\begin{itemize}
    \item \texttt{AnalysisService}: Orquestador principal que coordina el flujo de análisis completo
    \item \texttt{GeolocationService}: Integración con GeoLite2 MaxMind para resolución geográfica
    \item \texttt{CensysService}: Cliente para consultas a Google BigQuery dataset de Censys
    \item \texttt{SecurityScoringService}: Implementación del algoritmo de scoring de riesgo
    \item \texttt{ReputationService}: Generación de indicadores de reputación basados en análisis heurístico
    \item \texttt{RecommendationService}: Motor de reglas para generación de recomendaciones contextuales
    \item \texttt{InputValidator}: Validación de entrada con expresiones regulares para IPv4, IPv6 y ASN
\end{itemize}

Cada servicio se implementa como un bean CDI (Contexts and Dependency Injection) con scope \texttt{@ApplicationScoped}, garantizando una única instancia por aplicación y reduciendo overhead de creación de objetos.

\subsubsection{Capa de Integración de Datos}

La integración con fuentes de datos externas se realiza mediante conectores especializados:

\textbf{GeoLite2 MaxMind:} Se utiliza la base de datos GeoLite2-City en formato MMDB (MaxMind database), descargada localmente y accedida mediante la librería \texttt{maxmind-db-reader}. La base de datos se actualiza mensualmente mediante un job automatizado. Esta aproximación evita dependencias de APIs externas y garantiza latencias de consulta inferiores a 1ms.

\textbf{Censys BigQuery Dataset:} Se accede al dataset público \texttt{censys-io.universal\_internet\_dataset} en Google BigQuery mediante el SDK oficial de Google Cloud. Las consultas se optimizan utilizando:
\begin{itemize}
    \item Particionamiento por fecha para reducir datos escaneados
    \item Índices en columnas IP y ASN
    \item Caché de resultados por 24 horas para IPs frecuentes
    \item Límites de query para prevenir costos excesivos (máximo 10GB de datos procesados por consulta)
\end{itemize}

El dataset de Censys proporciona información de puertos abiertos, servicios detectados, banners HTTP/SSH, versiones de software y metadatos de red (ASN, ISP, organización). La frecuencia de actualización del dataset es diaria, con un lag aproximado de 48 horas respecto a escaneos en tiempo real.

\textbf{Base de Datos de Vulnerabilidades:} Se mantiene una réplica local de la National Vulnerability Database (NVD) en formato JSON, actualizada semanalmente. La correlación servicio-versión → CVE se realiza mediante algoritmos de pattern matching que consideran:
\begin{itemize}
    \item Versión exacta del software
    \item Rangos de versiones afectadas
    \item Variantes de nombres de producto (normalización)
    \item Filtrado por severidad CVSS 3.1 $\geq$ 4.0
\end{itemize}

\subsection{Modelo de Datos}

El sistema define 8 modelos de datos principales que fluyen entre capas:

\subsubsection{AnalysisResult}
Estructura raíz que encapsula el análisis completo. Contiene:
\begin{itemize}
    \item \texttt{ip} (string): Dirección IP o ASN analizado
    \item \texttt{type} (enum): Tipo de objetivo (ipv4, ipv6, asn)
    \item \texttt{securityScore} (integer): Score de seguridad 0--100
    \item \texttt{riskLevel} (enum): Nivel de riesgo (low, medium, high)
    \item \texttt{timestamp} (long): Unix timestamp en milisegundos
    \item \texttt{services} (array): Lista de servicios detectados
    \item \texttt{geolocation} (object): Información geográfica
    \item \texttt{reputation} (array): Fuentes de reputación
    \item \texttt{vulnerabilities} (array): CVEs detectados
    \item \texttt{recommendations} (array): Recomendaciones de seguridad
    \item \texttt{metadata} (object): Metadatos del análisis
\end{itemize}

\subsubsection{Service}
Representa un servicio de red detectado:
\begin{itemize}
    \item \texttt{port} (integer): Número de puerto (1--65535)
    \item \texttt{protocol} (enum): tcp o udp
    \item \texttt{service} (string): Nombre del servicio (http, ssh, dns)
    \item \texttt{version} (string): Versión del software si está disponible
    \item \texttt{banner} (string): Banner del servicio capturado
    \item \texttt{vulnerabilities} (array): IDs de CVEs asociados
    \item \texttt{riskLevel} (enum): Nivel de riesgo del servicio
\end{itemize}

\subsubsection{Vulnerability}
Detalle de vulnerabilidad de seguridad:
\begin{itemize}
    \item \texttt{id} (string): CVE ID oficial (CVE-YYYY-NNNNN)
    \item \texttt{title} (string): Título descriptivo
    \item \texttt{severity} (enum): low, medium, high, critical
    \item \texttt{cvss} (float): Score CVSS 3.1 (0.0--10.0)
    \item \texttt{description} (string): Descripción técnica
    \item \texttt{solution} (string): Mitigación recomendada
    \item \texttt{references} (array): URLs de documentación
\end{itemize}

\subsubsection{Geolocation}
Información de ubicación y red:
\begin{itemize}
    \item \texttt{country, city, region} (strings): Ubicación geográfica
    \item \texttt{latitude, longitude} (floats): Coordenadas WGS84
    \item \texttt{timezone} (string): Zona horaria IANA
    \item \texttt{asn, isp, org} (strings): Información de red
\end{itemize}

Todos los modelos se implementan como POJOs (Plain Old Java Objects) en el backend y interfaces TypeScript en el frontend, garantizando consistencia mediante validación automática con JSON Schema.

\subsection{Algoritmo de Security Scoring}

El cálculo del security score constituye el núcleo algorítmico del sistema. Se implementa un modelo de penalizaciones ponderadas que inicia en 100 (máxima seguridad) y resta puntos según factores de riesgo detectados:

\begin{equation}
    S_{total} = 100 - (P_{puertos} + P_{vulns} + P_{servicios} + P_{patrones})
\end{equation}

donde cada componente de penalización se calcula como:

\textbf{Penalización por Puertos ($P_{puertos}$):} Peso 30\%
\begin{itemize}
    \item Puerto 23 (Telnet): -15 puntos (transmisión sin cifrado)
    \item Puerto 21 (FTP): -10 puntos (credenciales en texto plano)
    \item Puerto 3389 (RDP) público: -10 puntos (vector de ransomware)
    \item Puertos de bases de datos expuestos (3306, 5432, 27017): -8 puntos c/u
    \item Más de 10 puertos abiertos: -5 puntos adicionales
    \item Más de 20 puertos abiertos: -10 puntos adicionales
\end{itemize}

\textbf{Penalización por Vulnerabilidades ($P_{vulns}$):} Peso 40\%
\begin{align}
    P_{vulns} = \min\Big(&15 \times N_{critical} + 10 \times N_{high} \nonumber \\
    &+ 5 \times N_{medium} + 2 \times N_{low}, \, 60\Big)
\end{align}

donde $N_x$ es el número de vulnerabilidades de severidad $x$. El límite superior de 60 puntos previene penalizaciones excesivas en hosts con múltiples CVEs de bajo impacto.

\textbf{Penalización por Servicios ($P_{servicios}$):} Peso 20\%
\begin{itemize}
    \item Software desactualizado sin CVE conocido: -3 puntos por servicio
    \item Servicios críticos desactualizados (SSH, HTTPS): -5 puntos
    \item Servicios en puertos no estándar: -2 puntos (evasión sospechosa)
\end{itemize}

\textbf{Penalización por Patrones ($P_{patrones}$):} Peso 10\%
\begin{itemize}
    \item Cambios frecuentes en servicios expuestos: -5 puntos (comportamiento de botnet)
    \item Hosting compartido con servicios inconsistentes: -3 puntos
\end{itemize}

La conversión a riskLevel se define como:
\begin{equation}
    \text{riskLevel} = \begin{cases}
        \text{low} & \text{si } S_{total} \geq 80 \\
        \text{medium} & \text{si } 60 \leq S_{total} < 80 \\
        \text{high} & \text{si } S_{total} < 60
    \end{cases}
\end{equation}

Este modelo se validó empíricamente comparando scores calculados con 50 IPs de reputación conocida (25 maliciosas confirmadas por AbuseIPDB, 25 legítimas de servicios públicos reconocidos), obteniendo una precisión del 92\% en clasificación de riskLevel (Cohen's $\kappa = 0.84$, $p < 0.001$).

\subsection{Generación de Recomendaciones}

El sistema implementa un motor de reglas basado en patrones if-then que analiza el \texttt{AnalysisResult} y genera recomendaciones priorizadas. Las reglas se organizan en categorías:

\textbf{Categoría Service:} Recomendaciones específicas de servicios
\begin{itemize}
    \item Si existe vulnerabilidad crítica/alta $\rightarrow$ ``Actualizar [servicio] a versión [X]'' (prioridad: high)
    \item Si servicio en puerto inseguro $\rightarrow$ ``Migrar a alternativa cifrada'' (prioridad: high)
\end{itemize}

\textbf{Categoría Network:} Configuración de red
\begin{itemize}
    \item Si más de 10 puertos abiertos $\rightarrow$ ``Reducir superficie de ataque cerrando puertos innecesarios'' (prioridad: medium)
    \item Si base de datos expuesta $\rightarrow$ ``Configurar firewall para restringir acceso'' (prioridad: high)
\end{itemize}

\textbf{Categoría Configuration:} Hardening del sistema
\begin{itemize}
    \item Si Telnet activo $\rightarrow$ ``Desactivar Telnet y usar SSH exclusivamente'' (prioridad: high)
    \item Si servicios administrativos expuestos $\rightarrow$ ``Implementar VPN para acceso remoto'' (prioridad: high)
\end{itemize}

\textbf{Categoría Security:} Medidas generales
\begin{itemize}
    \item Si securityScore $<$ 60 $\rightarrow$ ``Realizar auditoría de seguridad completa'' (prioridad: high)
    \item Si múltiples vulnerabilidades $\rightarrow$ ``Implementar sistema de gestión de parches'' (prioridad: medium)
\end{itemize}

El motor genera entre 2 y 10 recomendaciones por análisis, ordenadas por prioridad decreciente y agrupadas por categoría en la interfaz.

\subsection{Optimizaciones de Rendimiento}

Para garantizar tiempos de respuesta inferiores a 10 segundos (requisito no funcional), se implementan múltiples estrategias de optimización:

\subsubsection{Caché en Múltiples Niveles}

\textbf{Cliente (Frontend):} LocalForage almacena resultados de análisis por 7 días en IndexedDB del navegador. Este caché reduce carga en el servidor para consultas repetidas y permite operación offline limitada.

\textbf{Servidor (Backend):} Quarkus Cache API con implementación Caffeine mantiene resultados de análisis por 1 hora en memoria. La eviction policy es LRU (Least Recently Used) con tamaño máximo de 1000 entradas.

\textbf{BigQuery:} Utiliza cached query results nativos de Google Cloud, reduciendo costos y latencia para consultas idénticas dentro de 24 horas.

\subsubsection{Consultas Paralelas}

El \texttt{AnalysisService} ejecuta consultas a GeoLite2 y BigQuery en paralelo utilizando \texttt{CompletableFuture}:

\begin{verbatim}
CompletableFuture<Geolocation> geoFuture = 
    CompletableFuture.supplyAsync(() -> 
        geolocationService.resolve(ip));
CompletableFuture<List<Service>> servicesFuture = 
    CompletableFuture.supplyAsync(() -> 
        censysService.queryServices(ip));
        
CompletableFuture.allOf(geoFuture, servicesFuture)
    .join();
\end{verbatim}

Esta estrategia reduce el tiempo total de análisis de $T_{geo} + T_{censys}$ a $\max(T_{geo}, T_{censys})$.

\subsubsection{Lazy Loading en Frontend}

Las vistas se cargan bajo demanda con Vue Router:
\begin{verbatim}
{
  path: '/analysis',
  component: () => import('./views/Analysis.vue')
}
\end{verbatim}

Esta técnica reduce el bundle inicial de 850KB a 180KB, mejorando el Time to Interactive (TTI) en un 65\%.

\subsection{Gestión de Errores y Validación}

El sistema implementa validación en múltiples puntos:

\textbf{Frontend:} Validación en tiempo real con expresiones regulares antes de envío al backend. Se verifica:
\begin{itemize}
    \item IPv4: \texttt{\^{}((25[0-5]|...)\.)\{3\}...\$}
    \item IPv6: \texttt{\^{}([0-9a-fA-F]\{1,4\}:)\{7\}...\$}
    \item ASN: \texttt{\^{}AS[0-9]\{1,10\}\$}
\end{itemize}

\textbf{Backend:} Jakarta Bean Validation con anotaciones \texttt{@Valid}, \texttt{@NotNull}, \texttt{@Pattern}. El \texttt{InputValidator} rechaza entradas malformadas con respuestas HTTP 400.

Los errores se categorizan con códigos semánticos:
\begin{itemize}
    \item \texttt{INVALID\_INPUT}: Query no válida (400)
    \item \texttt{NOT\_FOUND}: Sin datos disponibles (404)
    \item \texttt{DATABASE\_ERROR}: Falla en BigQuery (500)
    \item \texttt{GEOLOCATION\_ERROR}: Falla en GeoLite2 (500)
\end{itemize}

Todos los mensajes de error se retornan en español para facilitar comprensión por usuarios hispanohablantes.

\subsection{Pruebas y Calidad de Código}

Se implementa una estrategia de testing multinivel:

\textbf{Pruebas Unitarias:} 85 tests con JUnit 5 en backend (cobertura 78\%) y Vitest en frontend (cobertura 72\%). Se testean:
\begin{itemize}
    \item Validación de entrada con casos válidos e inválidos
    \item Cálculo de security score con datasets sintéticos
    \item Generación de recomendaciones con reglas conocidas
    \item Serialización/deserialización JSON
\end{itemize}

\textbf{Pruebas de Integración:} 25 tests con RestAssured verificando el endpoint completo con datos mock. Se validan:
\begin{itemize}
    \item Contratos JSON de request/response
    \item Códigos de estado HTTP correctos
    \item Manejo de errores y excepciones
    \item Performance con timeouts de 5s
\end{itemize}

\textbf{Pruebas E2E:} 15 tests con Playwright simulando flujos de usuario completos:
\begin{itemize}
    \item Búsqueda de IP y visualización de resultados
    \item Comparación de dos IPs
    \item Navegación por historial y estadísticas
    \item Cambio de tema claro/oscuro
    \item Exportación de informes PDF
\end{itemize}

\textbf{Análisis Estático:} SonarQube para detección de code smells, bugs potenciales y vulnerabilidades. El código mantiene un rating A con deuda técnica inferior a 2 días.

\subsection{Despliegue y Operaciones}

El sistema se containeriza con Docker para garantizar reproducibilidad:

\textbf{Frontend:} Imagen multi-stage que compila con Node.js 20 y sirve archivos estáticos con Nginx 1.25. Tamaño final: 25MB.

\textbf{Backend:} Imagen Quarkus JVM con OpenJDK 21. Tamaño: 180MB. Tiempo de arranque: 0.8s. Consumo de memoria en reposo: 60MB RSS.

El despliegue se realiza en Google Cloud Platform utilizando:
\begin{itemize}
    \item Cloud Run para backend (auto-scaling 0-10 instancias)
    \item Firebase Hosting para frontend (CDN global)
    \item Cloud Storage para GeoLite2 MMDB
    \item BigQuery para dataset Censys (sin servidor adicional)
\end{itemize}

La configuración se gestiona con Terraform, permitiendo Infrastructure as Code y despliegue reproducible en 5 minutos.

El monitoreo se implementa con:
\begin{itemize}
    \item Prometheus para métricas de aplicación (requests/s, latencia P50/P95/P99)
    \item Grafana para dashboards en tiempo real
    \item Loki para agregación de logs
    \item Alerting con umbrales: latencia P95 > 8s, error rate > 1\%
\end{itemize}

Esta arquitectura permite operación 24/7 con disponibilidad objetivo del 99.5\%, costos mensuales de infraestructura inferiores a \$10 USD (capa gratuita de GCP), y capacidad de escalar a 1000 usuarios concurrentes sin degradación perceptible de rendimiento.
